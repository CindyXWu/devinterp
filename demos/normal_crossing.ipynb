{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "\n",
    "sys.path.insert(1, \"/home/paperspace/devinterp\") # TODO fix path\n",
    "\n",
    "from devinterp.slt.sampler import Sampler, SamplerConfig, estimate_rlct\n",
    "from torch.utils.data import TensorDataset\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, train_loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for data, target in tqdm(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data.to(DEVICE))\n",
    "        loss = criterion(output, target.to(DEVICE))\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return train_loss / len(train_loader)\n",
    "def train_one_batch(model, train_loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for data, target in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data.to(DEVICE))\n",
    "        loss = criterion(output, target.to(DEVICE))\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        break\n",
    "    return train_loss\n",
    "def evaluate(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = model(data.to(DEVICE))\n",
    "            loss = criterion(output, target.to(DEVICE))\n",
    "            test_loss += loss.item()\n",
    "    model.train()\n",
    "    return test_loss / len(test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PolyModel(nn.Module):\n",
    "    def __init__(self, powers):\n",
    "        super(PolyModel, self).__init__()\n",
    "        self.weights = nn.Parameter(torch.tensor([0., 0.],dtype=torch.float32, requires_grad=True))\n",
    "        self.powers = powers\n",
    "    def forward(self, x):\n",
    "        multiplied = torch.min(self.weights**self.powers)\n",
    "        x = x*multiplied\n",
    "        return x\n",
    "\n",
    "# criterion = nn.MSELoss()\n",
    "powers = torch.tensor([2, 2])\n",
    "model = PolyModel(powers)\n",
    "seed=0\n",
    "sigma=0.5\n",
    "lr=0.0001\n",
    "num_steps=2000\n",
    "num_train_samples = 5000\n",
    "num_test_samples = 1000\n",
    "batch_size=num_train_samples\n",
    "with_trajectory=False\n",
    "w_true = torch.zeros_like(powers)\n",
    "\n",
    "x = torch.normal(0, 2, size=(num_train_samples,))\n",
    "y = sigma * torch.normal(0, 1, size=(num_train_samples,))\n",
    "train_data = TensorDataset(x, y)\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "x_test = torch.normal(0, 2, size=(num_test_samples,))\n",
    "y_test =  sigma * torch.normal(0, 1, size=(num_test_samples,))\n",
    "test_data = TensorDataset(x_test, y_test)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=0.01)\n",
    "\n",
    "# train model\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "rlct_estimates = []\n",
    "models = []\n",
    "test_loss = 0.\n",
    "n_epochs = 20\n",
    "n_steps = 40\n",
    "\n",
    "def print_rlcts(SGNHT_config, SGLD_config):\n",
    "    rlct_estimates_sgnht = []\n",
    "    rlct_estimates_sgdl = []\n",
    "    for epoch in range(n_epochs):\n",
    "        # loss = train_one_epoch(model, train_loader, optimizer, criterion)\n",
    "        # test_loss = evaluate(model, test_loader, criterion)\n",
    "        # print(f\"Epoch {epoch+1}, Train Loss: {loss}, Test Loss: {test_loss}\")\n",
    "        # print(model.state_dict()['weights'])\n",
    "        model_for_rlct= copy.deepcopy(model)\n",
    "        model_for_rlct2= copy.deepcopy(model)\n",
    "        sgnht_sampler = Sampler(model_for_rlct, train_data, SGNHT_config)\n",
    "        sgdl_sampler = Sampler(model_for_rlct2, train_data, SGLD_config)\n",
    "        rlct_estimate_sgnht = sgnht_sampler.sample(summary_fn=estimate_rlct)\n",
    "        rlct_estimate_sgdl = sgdl_sampler.sample(summary_fn=estimate_rlct)\n",
    "        rlct_estimates_sgnht += [rlct_estimate_sgnht]\n",
    "        rlct_estimates_sgdl += [rlct_estimate_sgdl]\n",
    "        print(rlct_estimate_sgnht, rlct_estimate_sgdl)\n",
    "        # raise Exception\n",
    "    plt.hist(rlct_estimates_sgnht,alpha = 0.5, label='sgnht')\n",
    "    plt.hist(rlct_estimates_sgdl,alpha = 0.5, label='sgdl')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.70883560180664 0.15305842459201813\n",
      "52.057525634765625 0.08763440698385239\n",
      "41.39814376831055 0.12417352944612503\n",
      "47.85388946533203 0.08077621459960938\n",
      "64.03759765625 0.0320165641605854\n",
      "75.64456939697266 0.0926293432712555\n",
      "74.22412872314453 0.16498152911663055\n",
      "52.45056915283203 0.03957457095384598\n",
      "85.16056823730469 0.08606857061386108\n",
      "48.357059478759766 0.07203727215528488\n",
      "81.48987579345703 0.16176237165927887\n",
      "65.49381256103516 0.05447189882397652\n"
     ]
    }
   ],
   "source": [
    "# Initialize sgnht sampler\n",
    "SGNHT_config = SamplerConfig(\n",
    "    optimizer_config=dict(\n",
    "        optimizer_type=\"SGNHT\",\n",
    "        lr=lr,\n",
    "        diffusion_factor=0.01,\n",
    "        bounding_box_size=1.,\n",
    "        num_samples=len(train_data),\n",
    "        batch_size = batch_size,\n",
    "    ),\n",
    "    num_chains=1,\n",
    "    num_draws_per_chain=2_000,\n",
    "    num_burnin_steps=0,\n",
    "    num_steps_bw_draws=1,\n",
    "    batch_size=batch_size,         \n",
    "    criterion = 'mse_loss' \n",
    ")\n",
    "SGLD_config = SamplerConfig(\n",
    "    optimizer_config=dict(\n",
    "        optimizer_type=\"SGLD\",\n",
    "        lr=lr,\n",
    "        noise_level=.9,\n",
    "        weight_decay=0.1,\n",
    "        elasticity=1,\n",
    "        temperature='adaptive',\n",
    "        num_samples=len(train_data),\n",
    "    ),\n",
    "    num_chains=1,\n",
    "    num_draws_per_chain=10_000,\n",
    "    num_burnin_steps=0,\n",
    "    num_steps_bw_draws=1,\n",
    "    verbose=False,\n",
    "    batch_size=batch_size,         \n",
    "    criterion = 'mse_loss'\n",
    ")\n",
    "print_rlcts(SGNHT_config, SGLD_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
